Traceback (most recent call last):
  File "/scr/glebs/deps/anaconda3/envs/softlearning/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 261, in _process_events
    result = self.trial_executor.fetch_result(trial)
  File "/scr/glebs/deps/anaconda3/envs/softlearning/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 211, in fetch_result
    result = ray.get(trial_future[0])
  File "/scr/glebs/deps/anaconda3/envs/softlearning/lib/python3.6/site-packages/ray/worker.py", line 2386, in get
    raise value
ray.worker.RayTaskError: [36mray_ExperimentRunner:train()[39m (pid=23920, host=sadigh-ws-1.stanford.edu)
  File "/scr/glebs/deps/anaconda3/envs/softlearning/lib/python3.6/site-packages/ray/tune/trainable.py", line 146, in train
    result = self._train()
  File "/scr/glebs/dev/softlearning/examples/development/main.py", line 79, in _train
    diagnostics = next(self.train_generator)
  File "/scr/glebs/dev/softlearning/softlearning/algorithms/rl_algorithm.py", line 135, in _train
    env, initial_exploration_policy, pool)
  File "/scr/glebs/dev/softlearning/softlearning/algorithms/rl_algorithm.py", line 79, in _initial_exploration_hook
    self.sampler.sample()
  File "/scr/glebs/dev/softlearning/softlearning/samplers/simple_sampler.py", line 21, in sample
    self._current_observation = self.env.reset()
  File "/scr/glebs/dev/softlearning/softlearning/environments/adapters/fetch_adapter.py", line 118, in reset
    return self._env.reset(*args, **kwargs)
  File "/scr/glebs/deps/anaconda3/envs/softlearning/lib/python3.6/site-packages/gym/core.py", line 335, in reset
    return self.env.reset()
  File "/scr/glebs/dev/softlearning/softlearning/environments/fetch/real_fetch_env.py", line 211, in reset
    return self._get_obs()
  File "/scr/glebs/dev/softlearning/softlearning/environments/fetch/real_fetch_env.py", line 225, in _get_obs
    self.xg,
ValueError: all the input arrays must have same number of dimensions

